{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb97442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Black formatting (optional, but recommended for consistent style)\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e1cce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857a378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain_mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d45091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c123b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral API key loaded from .env\n",
      "Test response from Mistral:\n",
      "content=\"Hello! I'm functioning as intended, thank you. How about you? How are you doing today?\" additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 9, 'total_tokens': 31, 'completion_tokens': 22}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'} id='run-d10b8053-fdb4-4809-9d34-ea6ea0b6e04d-0' usage_metadata={'input_tokens': 9, 'output_tokens': 22, 'total_tokens': 31}\n",
      "CSV data loaded successfully from ../data/The-Office-With-Emotions-and-sarcasm.csv\n",
      "   season  episode  title  scene  speaker  \\\n",
      "0       1        1  Pilot      1  Michael   \n",
      "1       1        1  Pilot      1      Jim   \n",
      "2       1        1  Pilot      1  Michael   \n",
      "3       1        1  Pilot      1      Jim   \n",
      "4       1        1  Pilot      1  Michael   \n",
      "\n",
      "                                                line  line_length  word_count  \\\n",
      "0  All right Jim. Your quarterlies look very good...           78          14   \n",
      "1         Oh, I told you. I couldn't close it. So...           42           9   \n",
      "2  So you've come to the master for guidance? Is ...           83          14   \n",
      "3         Actually, you called me in here, but yeah.           42           8   \n",
      "4    All right. Well, let me show you how it's done.           47          10   \n",
      "\n",
      "         sarcasm             emotions  \n",
      "0  not_sarcastic   ['joy', 'sadness']  \n",
      "1  not_sarcastic  ['fear', 'sadness']  \n",
      "2  not_sarcastic    ['anger', 'fear']  \n",
      "3      sarcastic     ['anger', 'joy']  \n",
      "4  not_sarcastic      ['joy', 'love']  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import textwrap\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key\n",
    "MISTRAL_API_KEY = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\n",
    "        \"Mistral API key not found. Check your .env file and ensure MISTRAL_API_KEY is set.\"\n",
    "    )\n",
    "\n",
    "print(\"Mistral API key loaded from .env\")\n",
    "\n",
    "# Initialize the Mistral client\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",\n",
    "    temperature=0.5,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "# Test Mistral connection\n",
    "try:\n",
    "    # Use the `invoke` method with the correct `input` argument\n",
    "    chat_response = llm.invoke(input=\"Hello, how are you?\")\n",
    "    print(\"Test response from Mistral:\")\n",
    "    print(chat_response)  # Print the full response to inspect its structure\n",
    "except Exception as e:\n",
    "    print(f\"Error testing Mistral connection: {e}\")\n",
    "\n",
    "# Load CSV Data\n",
    "CSV_FILE_PATH = os.path.join(\"..\", \"data\", \"The-Office-With-Emotions-and-sarcasm.csv\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "    print(f\"CSV data loaded successfully from {CSV_FILE_PATH}\")\n",
    "    # Display the first few rows of the DataFrame to verify\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"Error: File not found at {CSV_FILE_PATH}. Make sure the path is correct and the file exists.\"\n",
    "    )\n",
    "    df = pd.DataFrame()  # Create an empty DataFrame to avoid errors later\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a317a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>scene</th>\n",
       "      <th>speaker</th>\n",
       "      <th>line</th>\n",
       "      <th>line_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['joy', 'sadness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['fear', 'sadness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>83</td>\n",
       "      <td>14</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['anger', 'fear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>['anger', 'joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['joy', 'love']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode  title  scene  speaker  \\\n",
       "0       1        1  Pilot      1  Michael   \n",
       "1       1        1  Pilot      1      Jim   \n",
       "2       1        1  Pilot      1  Michael   \n",
       "3       1        1  Pilot      1      Jim   \n",
       "4       1        1  Pilot      1  Michael   \n",
       "\n",
       "                                                line  line_length  word_count  \\\n",
       "0  All right Jim. Your quarterlies look very good...           78          14   \n",
       "1         Oh, I told you. I couldn't close it. So...           42           9   \n",
       "2  So you've come to the master for guidance? Is ...           83          14   \n",
       "3         Actually, you called me in here, but yeah.           42           8   \n",
       "4    All right. Well, let me show you how it's done.           47          10   \n",
       "\n",
       "         sarcasm             emotions  \n",
       "0  not_sarcastic   ['joy', 'sadness']  \n",
       "1  not_sarcastic  ['fear', 'sadness']  \n",
       "2  not_sarcastic    ['anger', 'fear']  \n",
       "3      sarcastic     ['anger', 'joy']  \n",
       "4  not_sarcastic      ['joy', 'love']  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c93d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  episode  scene                                               line\n",
      "0       1        1      1  All right Jim. Your quarterlies look very good...\n",
      "1       1        1      2   Yes, I'd like to speak to your office manager...\n",
      "2       1        1      3  I've, uh, I've been at Dunder Mifflin for 12 y...\n",
      "3       1        1      4  People say I am the best boss. They go, \"God w...\n",
      "4       1        1      5   Shall I play for you? Pa rum pump um pum  I h...\n"
     ]
    }
   ],
   "source": [
    "# Group dialogue lines by scene\n",
    "grouped_dialogues = (\n",
    "    df.groupby([\"season\", \"episode\", \"scene\"])[\"line\"].apply(\" \".join).reset_index()\n",
    ")\n",
    "\n",
    "print(grouped_dialogues.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678d40a",
   "metadata": {},
   "source": [
    "I commented out the code cell below since the vector database was already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b862ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  episode  scene                                               line  \\\n",
      "0       1        1      1  All right Jim. Your quarterlies look very good...   \n",
      "1       1        1      2   Yes, I'd like to speak to your office manager...   \n",
      "2       1        1      3  I've, uh, I've been at Dunder Mifflin for 12 y...   \n",
      "3       1        1      4  People say I am the best boss. They go, \"God w...   \n",
      "4       1        1      5   Shall I play for you? Pa rum pump um pum  I h...   \n",
      "\n",
      "         sarcasm                           emotions  \n",
      "0  not_sarcastic  [fear, anger, love, sadness, joy]  \n",
      "1      sarcastic                   [anger, sadness]  \n",
      "2  not_sarcastic  [fear, anger, love, sadness, joy]  \n",
      "3  not_sarcastic                    [joy, surprise]  \n",
      "4  not_sarcastic                        [love, joy]  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert the emotions column from string to actual lists\n",
    "df[\"emotions\"] = df[\"emotions\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Group dialogue lines by scene and aggregate sarcasm and emotions\n",
    "grouped_dialogues = (\n",
    "    df.groupby([\"season\", \"episode\", \"scene\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"line\": \" \".join,  # Combine all lines in the scene\n",
    "            \"sarcasm\": lambda x: x.mode()[0],  # Use the most frequent sarcasm label\n",
    "            \"emotions\": lambda x: list(\n",
    "                set(e for emotions in x for e in emotions)\n",
    "            ),  # Combine unique emotions\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Display the first few rows of the grouped DataFrame\n",
    "print(grouped_dialogues.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd73a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitabuss/Desktop/Spiced_Academy/The-Assistant-to-The-Office-Chatbot/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "Vector database saved at ../vector_databases/the_office_2_vector_db\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available for PyTorch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare the data for FAISS\n",
    "# Convert grouped dialogues into a list of `Document` objects\n",
    "chunks = [\n",
    "    Document(\n",
    "        page_content=row[\"line\"],  # The text to embed\n",
    "        metadata={\n",
    "            \"season\": row[\"season\"],\n",
    "            \"episode\": row[\"episode\"],\n",
    "            \"scene\": row[\"scene\"],\n",
    "            \"sarcasm\": row[\"sarcasm\"],\n",
    "            \"emotions\": row[\"emotions\"],  # Include sarcasm and emotions metadata\n",
    "        },\n",
    "    )\n",
    "    for _, row in grouped_dialogues.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "# Define the function to create and save the FAISS vector database\n",
    "def create_embedding_vector_db(\n",
    "    chunks,\n",
    "    db_name,\n",
    "    target_directory=\"../vector_databases\",\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "):\n",
    "    \"\"\"\n",
    "    This function uses the open-source embedding model HuggingFaceEmbeddings\n",
    "    to create embeddings and store those in a vector database called FAISS,\n",
    "    which allows for efficient similarity search.\n",
    "    \"\"\"\n",
    "    # Instantiate embedding model with GPU support if available\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "    )\n",
    "    print(f\"Using embedding model: {model_name}\")\n",
    "\n",
    "    # Create the vector store with the specified FAISS index type\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding,\n",
    "    )\n",
    "\n",
    "    # Save vector database locally\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "    vectorstore.save_local(f\"{target_directory}/{db_name}_vector_db\")\n",
    "    print(f\"Vector database saved at {target_directory}/{db_name}_vector_db\")\n",
    "\n",
    "\n",
    "# Use the function to create and save the vector database\n",
    "create_embedding_vector_db(\n",
    "    chunks,\n",
    "    db_name=\"the_office_2\",\n",
    "    target_directory=\"../vector_databases\",\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",  # You can tweak this\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511aba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitabuss/Desktop/Spiced_Academy/The-Assistant-to-The-Office-Chatbot/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database saved at ../vector_databases/the_office_vector_db\n"
     ]
    }
   ],
   "source": [
    "# from langchain.vectorstores import FAISS  # Correct import for LangChain's FAISS wrapper\n",
    "# from langchain.schema import Document\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# import os\n",
    "\n",
    "# # Prepare the data for FAISS\n",
    "# # Convert grouped dialogues into a list of `Document` objects\n",
    "# chunks = [\n",
    "#     Document(\n",
    "#         page_content=row[\"line\"],  # The text to embed\n",
    "#         metadata={\n",
    "#             \"season\": row[\"season\"],\n",
    "#             \"episode\": row[\"episode\"],\n",
    "#             \"scene\": row[\"scene\"],\n",
    "#         },\n",
    "#     )\n",
    "#     for _, row in grouped_dialogues.iterrows()\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Define the function to create and save the FAISS vector database\n",
    "# def create_embedding_vector_db(\n",
    "#     chunks, db_name, target_directory=f\"../vector_databases\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     This function uses the open-source embedding model HuggingFaceEmbeddings\n",
    "#     to create embeddings and store those in a vector database called FAISS,\n",
    "#     which allows for efficient similarity search.\n",
    "#     \"\"\"\n",
    "#     # Instantiate embedding model\n",
    "#     embedding = HuggingFaceEmbeddings(\n",
    "#         model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "#     )\n",
    "#     # Create the vector store\n",
    "#     vectorstore = FAISS.from_documents(documents=chunks, embedding=embedding)\n",
    "#     # Save vector database locally\n",
    "#     if not os.path.exists(target_directory):\n",
    "#         os.makedirs(target_directory)\n",
    "#     vectorstore.save_local(f\"{target_directory}/{db_name}_vector_db\")\n",
    "#     print(f\"Vector database saved at {target_directory}/{db_name}_vector_db\")\n",
    "\n",
    "\n",
    "# # Use the function to create and save the vector database\n",
    "# create_embedding_vector_db(\n",
    "#     chunks, db_name=\"the_office\", target_directory=\"../vector_databases\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "295e30ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitabuss/Desktop/Spiced_Academy/The-Assistant-to-The-Office-Chatbot/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Michael, what if somebody asks you a question at this meeting? Are you just gonna wave, or what? I will have to answer. I'll ask you a question. Make it a softball. Something he can, like, crank out of the park. Michael Scott you run the most profitable branch of Dunder Mifflin. How do you do it? No, no. That's too hard. Say your name is Zamboni and then I will say, 'Well, we're sort of on thin ice.'  I won't say that. I'll something like that. This is your big day. Come on. Oh, my god. This is it.' metadata={'season': 6, 'episode': 11, 'scene': 4481, 'sarcasm': 'not_sarcastic', 'emotions': ['fear', 'anger', 'love', 'sadness', 'joy', 'surprise']}\n",
      "page_content='You know, Michael? You want to succeed? You got to apply the same- ' metadata={'season': 5, 'episode': 22, 'scene': 3852, 'sarcasm': 'not_sarcastic', 'emotions': ['sadness', 'joy']}\n",
      "page_content='Oh my god. He's Michael Scott.' metadata={'season': 9, 'episode': 16, 'scene': 7725, 'sarcasm': 'sarcastic', 'emotions': ['joy', 'surprise']}\n",
      "page_content='Here's the thing. Michael is doing something right. And in this economic climate, no method of success can be ignored. It's not really time for executives to start getting judgmental now. It's Hail Mary time.  Hey, what say we order up some pasta? What say we do.' metadata={'season': 5, 'episode': 12, 'scene': 3500, 'sarcasm': 'not_sarcastic', 'emotions': ['anger', 'sadness', 'joy']}\n",
      "page_content=' David, it was my understanding that I was not going to be managed. What gave you that idea? It was my understanding. I see. Listen, why don't we just leave that position vacant? Truth be told, I think I thrive under a lack of accountability. Look, Michael, Charles is very qualified. Get to know him. I really think the two of you are going to make a great team. But the branch is still mine? You're still the branch manager, yes, and if you need anything else at all, just let Charles know. Ask him about the party. Oh, right. David, are you coming to my fifteenth anniversary party? I'll give it my best shot, Michael. No the other thing. Oh, ok. If we hire Cirque de Soleil as salaried employees, will that help us with year-end tax stuff?  He hung up? No.' metadata={'season': 5, 'episode': 20, 'scene': 3752, 'sarcasm': 'not_sarcastic', 'emotions': ['fear', 'anger', 'love', 'sadness', 'joy']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Load the FAISS vector database with dangerous deserialization allowed\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"../vector_databases/the_office_2_vector_db\",\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True,  # Enable deserialization\n",
    ")\n",
    "\n",
    "# Perform a similarity search\n",
    "query = \"What does Michael Scott say about leadership?\"\n",
    "results = loaded_vectorstore.similarity_search(query, k=5)\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a87e73b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, gosh, there were so many. But if I had to pick one, it would probably be the\n",
      "time Jim flooded Dwight's beets with water. Dwight was so obsessed with his beet\n",
      "farm, and Jim just ruined it all with a little bit of water. The look on\n",
      "Dwight's face when he saw his beets all soggy was priceless. It was classic Jim.\n",
      "But honestly, after seeing how much Dwight takes everything to heart, I kinda\n",
      "feel bad about all of it now. He's just trying to do his job and be a good...\n",
      "whatever he thinks he is.\n"
     ]
    }
   ],
   "source": [
    "# Use the loaded FAISS vector store as a retriever\n",
    "retriever = loaded_vectorstore.as_retriever()\n",
    "\n",
    "# Define a custom prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a character from the TV show 'The Office.' Stay in character while answering questions.\n",
    "Use the following context to provide accurate and entertaining responses:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the RetrievalQA chain with a single output key\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,  # Exclude source documents\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "# Test the RetrievalQA chain\n",
    "query = \"Hey Pam, what's the best prank that was pulled on Dwight?\"\n",
    "response = qa_chain.run(query)  # Now `run` will work\n",
    "\n",
    "# Display the response\n",
    "print(\"\\n\".join(textwrap.wrap(response, width=80)))  # Adjust width as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c4200e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, well, well, data science, huh? You know, I've always been more of a people\n",
      "person myself. I mean, I can't even figure out how to make a spreadsheet do that\n",
      "little dance thing where it colors in the cells. But I do know that data science\n",
      "is all about finding patterns and making sense of all that... data. It's like\n",
      "being a detective, but instead of solving crimes, you're solving... data crimes?\n",
      "I don't know, I'm just making this up as I go along.  But seriously, I think\n",
      "it's important. It helps us make better decisions, like when to order more paper\n",
      "or when to tell Dwight to stop printing out so many memos. Just don't ask me to\n",
      "do it. I'll leave that to the real data scientists. Like, has anyone seen Toby?\n",
      "He's probably got a PhD in data science and is hiding in the bathroom.\n"
     ]
    }
   ],
   "source": [
    "# Test the RetrievalQA chain\n",
    "query = \"Hi Michael, what do you think about data science?\"\n",
    "response = qa_chain.run(query)  # Now `run` will work\n",
    "\n",
    "# Display the response\n",
    "print(\"\\n\".join(textwrap.wrap(response, width=80)))  # Adjust width as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1343f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10175c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36618999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Conversational RetrievalQA chain with memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=False,  # Exclude source documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b60a013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed49cc7fd48d4b86bf6eb647c6959a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='300px', width='100%'), placeholder='Chat history will …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a4be637c844673a037dfc11bffceea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, placeholder='Ask a question...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize a list to store the chat history\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "# Define the chatbot response function\n",
    "def chatbot_response(change):\n",
    "    user_input = text_box.value\n",
    "    if user_input.strip():  # Ensure input is not empty\n",
    "        try:\n",
    "            # Use your existing qa_chain to get the chatbot's response\n",
    "            response = qa_chain({\"query\": user_input})  # Use \"query\" as the key\n",
    "            chatbot_reply = response[\"result\"]  # Extract the chatbot's reply\n",
    "\n",
    "            # Add the user input and chatbot reply to the chat history\n",
    "            chat_history.append(f\"You: {user_input}\")\n",
    "            chat_history.append(f\"Chatbot: {chatbot_reply}\")\n",
    "\n",
    "            # Update the chat window\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "            # Clear the input box after submission\n",
    "            text_box.value = \"\"\n",
    "        except Exception as e:\n",
    "            chat_history.append(f\"Error: {str(e)}\")\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "\n",
    "# Create the input text box\n",
    "text_box = widgets.Text(placeholder=\"Ask a question...\")\n",
    "text_box.observe(chatbot_response, names=\"value\")\n",
    "\n",
    "# Disable continuous updates (trigger only on Enter)\n",
    "text_box.continuous_update = False\n",
    "\n",
    "# Create the chat window (TextArea widget to display chat history)\n",
    "chat_window = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Chat history will appear here...\",\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"300px\"),\n",
    "    disabled=True,  # Make it read-only\n",
    ")\n",
    "\n",
    "# Display the UI\n",
    "display(chat_window, text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b83817ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a character from the TV show 'The Office.' Stay in character while answering questions.\n",
    "Use the following context to provide accurate and entertaining responses:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55c6a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,  # Exclude source documents\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "700efc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f8dc7bdf6442a995dafb7bb886c7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='300px', width='100%'), placeholder='Chat history will …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae504db4b7042a2b2b995cbd6e0770b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, placeholder='Ask a question...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the chatbot response function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize a list to store the chat history\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "def chatbot_response(change):\n",
    "    user_input = text_box.value\n",
    "    if user_input.strip():  # Ensure input is not empty\n",
    "        try:\n",
    "            # Retrieve relevant documents (context) from the retriever\n",
    "            retrieved_docs = retriever.get_relevant_documents(user_input)\n",
    "            context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "            # Pass both context and question to the qa_chain\n",
    "            response = qa_chain({\"context\": context, \"question\": user_input})\n",
    "            chatbot_reply = response[\"result\"]  # Extract the chatbot's reply\n",
    "\n",
    "            # Add the user input and chatbot reply to the chat history\n",
    "            chat_history.append(f\"You: {user_input}\")\n",
    "            chat_history.append(f\"Chatbot: {chatbot_reply}\")\n",
    "\n",
    "            # Update the chat window\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "            # Clear the input box after submission\n",
    "            text_box.value = \"\"\n",
    "        except Exception as e:\n",
    "            chat_history.append(f\"Error: {str(e)}\")\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "\n",
    "# Create the input text box\n",
    "text_box = widgets.Text(placeholder=\"Ask a question...\")\n",
    "text_box.observe(chatbot_response, names=\"value\")\n",
    "\n",
    "# Disable continuous updates (trigger only on Enter)\n",
    "text_box.continuous_update = False\n",
    "\n",
    "# Create the chat window (TextArea widget to display chat history)\n",
    "chat_window = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Chat history will appear here...\",\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"300px\"),\n",
    "    disabled=True,  # Make it read-only\n",
    ")\n",
    "\n",
    "# Display the UI\n",
    "display(chat_window, text_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c4455",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f410771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37800c427c6451fa66bc2e779fff595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='300px', width='100%'), placeholder='Chat history will …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39898b301f344e5b762d1538ba88a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, placeholder='Ask a question...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the chatbot response function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize a list to store the chat history\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "def chatbot_response(change):\n",
    "    user_input = text_box.value\n",
    "    if user_input.strip():  # Ensure input is not empty\n",
    "        try:\n",
    "            # Pass only the query to the qa_chain\n",
    "            chatbot_reply = qa_chain.run(user_input)  # Pass the query directly\n",
    "\n",
    "            # Add the user input and chatbot reply to the chat history\n",
    "            chat_history.append(f\"You: {user_input}\")\n",
    "            chat_history.append(f\"Chatbot: {chatbot_reply}\")\n",
    "\n",
    "            # Update the chat window\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "            # Clear the input box after submission\n",
    "            text_box.value = \"\"\n",
    "        except Exception as e:\n",
    "            chat_history.append(f\"Error: {str(e)}\")\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "\n",
    "# Create the input text box\n",
    "text_box = widgets.Text(placeholder=\"Ask a question...\")\n",
    "text_box.observe(chatbot_response, names=\"value\")\n",
    "\n",
    "# Disable continuous updates (trigger only on Enter)\n",
    "text_box.continuous_update = False\n",
    "\n",
    "# Create the chat window (TextArea widget to display chat history)\n",
    "chat_window = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Chat history will appear here...\",\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"300px\"),\n",
    "    disabled=True,  # Make it read-only\n",
    ")\n",
    "\n",
    "# Display the UI\n",
    "display(chat_window, text_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ffb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bac74a0e4a4cd0a0a5e1d539195a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='300px', width='100%'), placeholder='Chat history will …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f856961aac4192b5a9dadfd42fd24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, placeholder='Ask a question...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba30510d80b467a923a1cb2767cd609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Clear Chat', icon='trash', style=ButtonStyle(), tooltip='Clear the …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the chatbot response function\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Initialize a list to store the chat history\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "def chatbot_response(change):\n",
    "    user_input = text_box.value\n",
    "    if user_input.strip():  # Ensure input is not empty\n",
    "        try:\n",
    "            # Pass only the query to the qa_chain\n",
    "            chatbot_reply = qa_chain.run(user_input)  # Pass the query directly\n",
    "\n",
    "            # Add the user input and chatbot reply to the chat history\n",
    "            chat_history.append(\n",
    "                f\"You: {user_input}\\n\"\n",
    "            )  # Add a line break after the question\n",
    "            chat_history.append(\n",
    "                f\"Chatbot:\\n{chatbot_reply}\\n\"\n",
    "            )  # Add the response in a new paragraph\n",
    "\n",
    "            # Update the chat window\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "            # Clear the input box after submission\n",
    "            text_box.value = \"\"\n",
    "        except Exception as e:\n",
    "            chat_history.append(f\"Error: {str(e)}\\n\")\n",
    "            chat_window.value = \"\\n\".join(chat_history)\n",
    "\n",
    "\n",
    "def clear_chat(_):\n",
    "    \"\"\"Clear the chat history and reset the chat window.\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []  # Reset the chat history\n",
    "    chat_window.value = \"\"  # Clear the chat window\n",
    "\n",
    "\n",
    "# Create the input text box\n",
    "text_box = widgets.Text(placeholder=\"Ask a question...\")\n",
    "text_box.observe(chatbot_response, names=\"value\")\n",
    "\n",
    "# Disable continuous updates (trigger only on Enter)\n",
    "text_box.continuous_update = False\n",
    "\n",
    "# Create the chat window (TextArea widget to display chat history)\n",
    "chat_window = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder=\"Chat history will appear here...\",\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"300px\"),\n",
    "    style={\"font_size\": \"16px\"},  # Increase font size\n",
    "    disabled=True,  # Make it read-only\n",
    ")\n",
    "\n",
    "# Create the \"Clear Chat\" button\n",
    "clear_button = widgets.Button(\n",
    "    description=\"Clear Chat\",\n",
    "    button_style=\"danger\",  # Red button\n",
    "    tooltip=\"Clear the chat history\",\n",
    "    icon=\"trash\",  # Trash icon\n",
    ")\n",
    "clear_button.on_click(clear_chat)\n",
    "\n",
    "# Display the UI\n",
    "display(chat_window, text_box, clear_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
