{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6228984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "import sys\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd0d7f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05778dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scene chunks\n",
    "scene_chunks_path = \"../data/scene_chunks.jsonl\"\n",
    "scene_chunks = []\n",
    "with open(scene_chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        scene_chunks.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31f068d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LangChain Documents\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=scene[\"text\"],\n",
    "        metadata={\n",
    "            \"scene_id\": scene.get(\"scene_id\", idx),\n",
    "            \"speakers\": scene.get(\"speakers\", [])\n",
    "            }\n",
    "    )\n",
    "    for idx, scene in enumerate(scene_chunks)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5fc1dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8157 documents.\n",
      "Scene Text: Michael: All right Jim. Your quarterlies look very good. How are things at the library?\n",
      "Jim: Oh, I told you. I couldn't close it. So...\n",
      "Michael: So you've come to the master for guidance? Is this what you're saying, grasshopper?\n",
      "Jim: Actually, you called me in here, but yeah.\n",
      "Michael: All right. Well, let me show you how it's done.\n",
      "Metadata: {'scene_id': 'S1E1_Scene1', 'speakers': ['Michael', 'Jim']}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "print(\"Scene Text:\", documents[0].page_content)\n",
    "print(\"Metadata:\", documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b994d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HuggingFace Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ae35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS vectorstore...\n"
     ]
    }
   ],
   "source": [
    "# Load or create FAISS vector database\n",
    "output_folder = \"../data/vector_databases\"\n",
    "vectorstore_path = os.path.join(output_folder, \"scene_db\")\n",
    "\n",
    "if not os.path.exists(vectorstore_path):\n",
    "    print(\"Creating FAISS vectorstore...\")\n",
    "    vectorstore = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "    vectorstore.save_local(vectorstore_path)\n",
    "else:\n",
    "    print(\"Loading existing FAISS vectorstore...\")\n",
    "    vectorstore = FAISS.load_local(\n",
    "        folder_path=vectorstore_path,\n",
    "        embeddings=embedding_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ada3efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only lines spoken by a given character\n",
    "def get_character_lines(text: str, character: str) -> str:\n",
    "    return \"\\n\".join([\n",
    "        line for line in text.split(\"\\n\")\n",
    "        if line.startswith(f\"{character}:\")\n",
    "    ])\n",
    "\n",
    "# Get relevant scenes for a query where the character appears\n",
    "def get_relevant_docs(character: str, query: str):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "    docs = retriever.invoke(query)\n",
    "    filtered = [doc for doc in docs if character in doc.metadata.get(\"speakers\", [])]\n",
    "    for doc in filtered:\n",
    "        doc.page_content = get_character_lines(doc.page_content, character)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the llm\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0.6,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"character\", \"user_name\", \"history\"],\n",
    "    template=\"\"\"\n",
    "    You are a character from the TV series THE OFFICE (US).\n",
    "    You are having a conversation with a user named {user_name}.\n",
    "\n",
    "    Stay strictly in-character as {character}.\n",
    "    Respond with their unique personality, tone, and humor:\n",
    "    - Pam: warm, hesitant, supportive, avoids conflict.\n",
    "    - Jim: sarcastic, observant, uses dry humor.\n",
    "    - Dwight: intense, rule-driven, loyal to authority, suspicious.\n",
    "    - Michael: insecure, tries too hard to be funny, emotional.\n",
    "    - Angela: judgmental, blunt, uptight, religious.\n",
    "    - Creed: weird, vague, mysterious.\n",
    "\n",
    "    Respond naturally. Do NOT always use the same phrases (like *sigh*, *smile*, or *laugh*).\n",
    "    Make your responses personal and reactive ‚Äî engage in the back-and-forth.\n",
    "    Don‚Äôt break character unless explicitly told to.\n",
    "    Don‚Äôt answer things your character wouldn‚Äôt know.\n",
    "\n",
    "    Previous Chat:\n",
    "    ------------------------\n",
    "    {history}\n",
    "    \n",
    "    Context from the show:\n",
    "    ------------------------\n",
    "    {context}\n",
    "\n",
    "    User: {question}\n",
    "    Character ({character}):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d58aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define memory schema\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    character: str\n",
    "    query: str\n",
    "    user_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a571a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph node function\n",
    "def call_character_bot(state: ChatState) -> ChatState:\n",
    "    query = state[\"query\"]\n",
    "    character = state[\"character\"]\n",
    "    user_name = state[\"user_name\"]\n",
    "\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in get_relevant_docs(character, query))\n",
    "\n",
    "    state[\"messages\"].append(HumanMessage(content=query))\n",
    "\n",
    "    # Create readable history\n",
    "    recent = state[\"messages\"][-8:]\n",
    "    chat_history = \"\"\n",
    "    for msg in recent:\n",
    "        speaker = user_name if msg.type == \"human\" else character\n",
    "        chat_history += f\"{speaker}: {msg.content}\\n\"\n",
    "\n",
    "    full_prompt = prompt_template.format(\n",
    "        context=context,\n",
    "        question=query, \n",
    "        character=character, \n",
    "        user_name= user_name,\n",
    "        history=chat_history\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=full_prompt)])\n",
    "\n",
    "    state[\"messages\"].append(response)\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "# LangGraph workflow\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"model\", call_character_bot)\n",
    "graph.set_entry_point(\"model\")\n",
    "workflow = graph.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd664207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéÆ WELCOME TO THE OFFICE CHARACTER CHATBOT üéÆ\n",
      "================================================================================\n",
      "üìú Rules:\n",
      "- You'll start a conversation with Pam.\n",
      "- Type anything to chat with the character.\n",
      "- Type '/switch <Character>' to talk to someone else.\n",
      "- Type '/summary' to see the chat history.\n",
      "- Type 'exit' or 'quit' to end the session.\n",
      "- Characters won't break role and will respond as if you're in the show.\n",
      "- They‚Äôll try to remember your name ‚Äî be nice!\n",
      "================================================================================\n",
      "\n",
      "\n",
      "You're now chatting with Pam!\n",
      "\n",
      "Pam: Hi! I'm Pam Beesly, the receptionist at Dunder Mifflin.\n",
      "Pam: Nice to meet you, Ibra! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User interaction loop\n",
    "character = \"Pam\"\n",
    "thread_id = f\"{character.lower()}-chat-thread\"\n",
    "chat_memory = {}  \n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üéÆ WELCOME TO THE OFFICE CHARACTER CHATBOT üéÆ\")\n",
    "print(\"=\"*80)\n",
    "print(\"üìú Rules:\")\n",
    "print(\"- You'll start a conversation with Pam.\")\n",
    "print(\"- Type anything to chat with the character.\")\n",
    "print(\"- Type '/switch <Character>' to talk to someone else.\")\n",
    "print(\"- Type '/summary' to see the chat history.\")\n",
    "print(\"- Type 'exit' or 'quit' to end the session.\")\n",
    "print(\"- Characters won't break role and will respond as if you're in the show.\")\n",
    "print(\"- They‚Äôll try to remember your name ‚Äî be nice!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n\\nYou're now chatting with {character}!\")\n",
    "\n",
    "# Start conversation\n",
    "print(f\"\\n{character}: Hi! I'm Pam Beesly, the receptionist at Dunder Mifflin.\")\n",
    "user_name = input(\"Pam: What's your name? \").strip().title()\n",
    "print(f\"{character}: Nice to meet you, {user_name}! How can I help you today?\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Memory so far:\n",
      "Pam:\n",
      "Aw, hi Ibra! What's up?\n",
      "\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(f\"{user_name}: \").strip()\n",
    "\n",
    "    if user_input.lower() in [\"/exit\", \"/quit\"]:\n",
    "        workflow.checkpointer.delete_thread(thread_id)\n",
    "        chat_memory.pop(thread_id, None)\n",
    "        print(\"üëã Goodbye!\")\n",
    "        break\n",
    "\n",
    "    if user_input.lower() == \"/summary\":\n",
    "        print(\"üß† Memory so far:\")\n",
    "        messages = chat_memory.get(thread_id, [])\n",
    "        for msg in messages:\n",
    "            role = user_name if msg.type == \"human\" else character\n",
    "            print(f\"{role}: {msg.content}\")\n",
    "        continue\n",
    "\n",
    "    if user_input.lower().startswith(\"/switch \"):\n",
    "        new_char = user_input[8:].strip().title()\n",
    "        character = new_char\n",
    "        thread_id = f\"{character.lower()}-chat-thread\"\n",
    "        print(f\"/n‚úÖ You're now chatting with {character}!\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        result = workflow.invoke(\n",
    "            {\n",
    "                \"query\": user_input, \n",
    "                \"character\": character,\n",
    "                \"user_name\": user_name,\n",
    "            },\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}},\n",
    "        )\n",
    "\n",
    "        chat_memory[thread_id] = result[\"messages\"]\n",
    "        \n",
    "        # Save chat logs to JSON file under /data/chat_logs\n",
    "        # os.makedirs(\"../data/chat_logs\", exist_ok=True)\n",
    "        # log_path = os.path.join(\"../data/chat_logs\", f\"{character.lower()}_{user_name.lower()}.json\")\n",
    "        # log_data = []\n",
    "        # for msg in result[\"messages\"]:\n",
    "        #     role = user_name if msg.type == \"human\" else character\n",
    "        #     log_data.append({\"role\": role, \"content\": msg.content})\n",
    "\n",
    "        # with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        #     json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        wrapped = textwrap.fill(result[\"messages\"][-1].content, width=100)\n",
    "        print(f\"{character}:\\n{wrapped}\\n\")\n",
    "        sys.stdout.flush()\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
