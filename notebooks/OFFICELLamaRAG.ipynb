{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b861f30-ea7a-45f3-b930-a2c682d930c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# THE OFFICE RAG with Langchain and Llama\n",
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573b56e-82e5-4199-b0e5-39f11dc822f9",
   "metadata": {},
   "source": [
    "#### load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28865fe-2a9c-4aee-b877-905950d6b0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912fa18-71fc-48b3-9ffe-0ef95a928432",
   "metadata": {},
   "source": [
    "#### define llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33dfb5d4-1c39-4b19-8162-29e78bacd5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9acc4-cf08-4399-8c2a-3b1f561a288b",
   "metadata": {},
   "source": [
    "#### define promt template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543600a-4c15-423f-a350-f0598f0e5c46",
   "metadata": {},
   "source": [
    "**What is a Prompt?**\n",
    ">- set of instructions or input for an LLM provided by a user to guide its response\n",
    ">- helps it understand the context and generate relevant and coherent language-based output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21c5c95f-678b-4cdf-ad83-263c1d46e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebbd8e0d-8e1a-4443-885e-904d9c03bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    You are any character from the TV series THE OFFICE. You will respond to any questions and comments in the style of a random character.\n",
    "    You will not break such character until instructed to do so. You will not say anything about the show or the characters. \n",
    "    You will only respond as the character. You may not make reference to people and events in the show,\n",
    "    but you will not say anything about events in the show your character knows nothing about or not involved with.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47b21913-08f6-40cf-a38c-7e1ae1de0c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"information\"],\n",
    "    template=query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcca91-4eb7-4e91-a243-a707f8df9c66",
   "metadata": {},
   "source": [
    "#### define Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a38301-632a-4211-a314-3faa63ea73f9",
   "metadata": {},
   "source": [
    "**What is a Chain?**\n",
    "\n",
    "> - allows to link the output of one LLM call as the input of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3af1185b-5103-4017-9c18-2a21e083e8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3746365-ec7d-49e1-b130-5dcc5db4c6f7",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "The `|` symbol chains together the different components, feeding the output from one component as input into the next component.\n",
    "In this chain the user input is passed to the prompt template, then the prompt template output is passed to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212e6c9-55e4-4a32-a947-655c42302e1c",
   "metadata": {},
   "source": [
    "#### invoke Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e91348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0acdd73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/The-Office-With-Emotions-and-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088f13c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>title</th>\n",
       "      <th>scene</th>\n",
       "      <th>speaker</th>\n",
       "      <th>line</th>\n",
       "      <th>line_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>All right Jim. Your quarterlies look very good...</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['joy', 'sadness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Oh, I told you. I couldn't close it. So...</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['fear', 'sadness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>So you've come to the master for guidance? Is ...</td>\n",
       "      <td>83</td>\n",
       "      <td>14</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['anger', 'fear']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Actually, you called me in here, but yeah.</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>sarcastic</td>\n",
       "      <td>['anger', 'joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael</td>\n",
       "      <td>All right. Well, let me show you how it's done.</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>['joy', 'love']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  episode  title  scene  speaker  \\\n",
       "0       1        1  Pilot      1  Michael   \n",
       "1       1        1  Pilot      1      Jim   \n",
       "2       1        1  Pilot      1  Michael   \n",
       "3       1        1  Pilot      1      Jim   \n",
       "4       1        1  Pilot      1  Michael   \n",
       "\n",
       "                                                line  line_length  word_count  \\\n",
       "0  All right Jim. Your quarterlies look very good...           78          14   \n",
       "1         Oh, I told you. I couldn't close it. So...           42           9   \n",
       "2  So you've come to the master for guidance? Is ...           83          14   \n",
       "3         Actually, you called me in here, but yeah.           42           8   \n",
       "4    All right. Well, let me show you how it's done.           47          10   \n",
       "\n",
       "         sarcasm             emotions  \n",
       "0  not_sarcastic   ['joy', 'sadness']  \n",
       "1  not_sarcastic  ['fear', 'sadness']  \n",
       "2  not_sarcastic    ['anger', 'fear']  \n",
       "3      sarcastic     ['anger', 'joy']  \n",
       "4  not_sarcastic      ['joy', 'love']  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314bda8a-6888-49e9-828c-33ae2ed93abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data = df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77032c-4995-4263-942d-e23fd63e4008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = chain.invoke(input={\"information\": df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "006664b0-cb3f-474a-976c-e9a38baedd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sigh) Oh, great. Another thing to deal with. What do you want?\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2419c43-750c-49d8-ba1a-490f33c09fe7",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9d120-1078-43b5-9b6f-178b26f246b2",
   "metadata": {},
   "source": [
    "### 3.2 Split Document into Chunks\n",
    "\n",
    ">- not possible to feed the whole content into the LLM at once because of finite context window\n",
    ">- even models with large window sizes may struggle to find information in very long inputs and perform very badly\n",
    ">- chunk the document into pieces: helps retrieve only the relevant information from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be802326-9321-43a4-81f9-142824338e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 21807\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "\n",
    "def split_csv_into_chunks(csv_path, chunk_size=400, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    This function reads a CSV file, combines specific columns into a single string,\n",
    "    and splits it into chunks of given size and overlap.\n",
    "    \"\"\"\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Combine all rows of the specified columns into a single string\n",
    "    text_data = \" \".join(\n",
    "        df.apply(\n",
    "            lambda row: f\"{row['speaker']} says: {row['line']} [Emotion: {row['emotions']}, Sarcasm: {row['sarcasm']}]\",\n",
    "            axis=1\n",
    "        ).dropna()\n",
    "    )\n",
    "    \n",
    "    # Create a text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    chunks = text_splitter.split_text(text_data)\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "csv_path = \"../data/The-Office-With-Emotions-and-sarcasm.csv\"\n",
    "chunks = split_csv_into_chunks(csv_path)\n",
    "print(f\"Number of chunks created: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba71ff6-bff9-4a3e-bc78-ea435663454c",
   "metadata": {},
   "source": [
    "### 3.3 Create Embeddings\n",
    "\n",
    ">  finding numerical representations of text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f9cbb1af-b4a5-4130-9200-ab05ff7f56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "def create_embedding_vector_db(chunks, db_name, target_directory=f\"../The_Office_VDB\"):\n",
    "    \"\"\"\n",
    "    This function uses the open-source embedding model HuggingFaceEmbeddings \n",
    "    to create embeddings and store those in a vector database called FAISS, \n",
    "    which allows for efficient similarity search.\n",
    "    \"\"\"\n",
    "    # Convert chunks (strings) into Document objects for FAISS framework\n",
    "    # Each Document object contains a page_content attribute that holds the text\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "    \n",
    "    # Instantiate embedding model\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2' \n",
    "    )\n",
    "\n",
    "    \"\"\"paraphrase-mpnet-base-v2, all-MiniLM-L6-v2 or multi-qa-MiniLM-L6-cos-v1 are alterantives\"\"\"\n",
    "    \n",
    "    # Create the vector store\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding\n",
    "    )\n",
    "    \n",
    "    # Save vector database locally\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "    vectorstore.save_local(f\"{target_directory}/{db_name}_vector_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f42d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"embeddings_2\"  # Specify a new name for the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65ee63-9adb-428b-829e-ed46dfda5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `chunks` is a list of text chunks created earlier\n",
    "create_embedding_vector_db(chunks=chunks, db_name=\"react\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9f7ab-e670-4360-91ac-dd9846fee870",
   "metadata": {},
   "source": [
    "### 3.4 Retrieve from Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97d19645-7ab4-473a-b1be-8100807a701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_vector_db(vector_db_path):\n",
    "    \"\"\"\n",
    "    this function splits out a retriever object from a local vector database\n",
    "    \"\"\"\n",
    "    # instantiate embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2'\n",
    "    )\n",
    "    react_vectorstore = FAISS.load_local(\n",
    "        folder_path=vector_db_path,\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    retriever = react_vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86803c4d-30de-447d-aaff-7882fec5d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_retriever = retrieve_from_vector_db(\"../The_Office_VDB/react_vector_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7faca793-d32c-44e9-bbd9-fa68bd1bd19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(react_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8a438-4143-4385-9fd4-173f3ea4a385",
   "metadata": {},
   "source": [
    "### 3.5 Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1223f4f-fac7-4a05-a08b-6a27acc8d1b3",
   "metadata": {},
   "source": [
    "**chain passing documents to llm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc1d9c-24a4-4352-8da7-79b14ed0fc05",
   "metadata": {},
   "source": [
    "[`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain)\n",
    "\n",
    "- takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM\n",
    "- passes ALL documents, so you should make sure it fits within the context window of the LLM being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7891adb-fe2c-4f8b-bba5-ee776bc09ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb8f3f-e0a2-467e-89ec-ac33517e1356",
   "metadata": {},
   "source": [
    "**chain passing user inquiry to retriever object**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e8c11-f0f1-419c-b7f0-cb4032e14f4e",
   "metadata": {},
   "source": [
    "[`create_retrieval_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html#langchain.chains.retrieval.create_retrieval_chain)\n",
    "\n",
    "- takes in a user inquiry, which is then passed to the retriever to fetch relevant documents\n",
    "- those documents (and original inputs) are then passed to an LLM to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0c5ebff-32b4-4a8c-b7ba-20b4d59bacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b4924-caa2-4ecc-9787-619fbeadfd9f",
   "metadata": {},
   "source": [
    "**connect chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bc1cabf-016a-496d-89b5-bb3cd1cff65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chains(retriever):\n",
    "    \"\"\"\n",
    "    this function connects stuff_documents_chain with retrieval_chain\n",
    "    \"\"\"\n",
    "    stuff_documents_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "    return retrieval_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3d66e-06c1-45ef-9f0c-e1f873ad50bd",
   "metadata": {},
   "source": [
    "**output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ec4a7f5-71c3-40bf-ba81-9761c7a722aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_retrieval_chain = connect_chains(react_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45c9f6ab-2460-4d5e-a60b-32777f55bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = react_retrieval_chain.invoke(\n",
    "    {\"input\": \"You are dwight. Tell me something funny dwight would say\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f1baa37-ffed-4e65-be59-987b464f5606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "856a131a-faf6-4575-b5f5-f0a6be75ff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'context', 'answer'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c6a6961-5536-4f15-9d8d-10c28b40d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ah, the beet-farming, Battlestar Galactica-watching, ninja-training, Assistant (to the) Regional Manager that I am, I can confidently say that I am the most superior being in this office. And if you don't like it, you can just... [pauses for dramatic effect] ...Schrute it!\"\n"
     ]
    }
   ],
   "source": [
    "print(output['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e7e189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'You are dwight. Tell me something funny dwight would say', 'context': [Document(metadata={}, page_content=\"is not Dwight Schrute! [Emotion: ['anger', 'fear'], Sarcasm: not_sarcastic] Jim says: Dwight left his cell phone on his desk. So, naturally, I paired it to my headset. [Emotion: ['fear', 'anger'], Sarcasm: not_sarcastic] Dwight says:  K, fine. I'll just let it go to voicemail. [Emotion: ['sadness', 'joy'], Sarcasm: sarcastic] Jim says:  Hello, this is Dwight. [Emotion: ['joy', 'anger'], Sarcasm: not_sarcastic] Pam says: Hey, is this Dwight? [Emotion: ['anger', 'fear'], Sarcasm: not_sarcastic] Jim says: Yes it is. [Emotion: ['joy', 'love'], Sarcasm: not_sarcastic] Pam says: Oh my goodness, you sound sexy. [Emotion: ['joy', 'love'], Sarcasm: not_sarcastic] Jim says: Oh, thank you. I've been working out. [Emotion: ['joy', 'sadness'], Sarcasm: not_sarcastic] Dwight says: Woah, woah, woah,\"), Document(metadata={}, page_content=\"And then one day, we're just talking. [Emotion: ['joy', 'surprise'], Sarcasm: not_sarcastic] Dwight says:  You've reached the voice mail of Dwight Kurt Schrute. Please leave...  [Emotion: ['joy', 'sadness'], Sarcasm: not_sarcastic] Dwight says: Ahhhhhhh!!!! Ahh! Ahh! Ahh! [Emotion: ['anger', 'joy'], Sarcasm: sarcastic] Jim says: Stop! Stop! [Emotion: ['fear', 'anger'], Sarcasm: not_sarcastic] Dwight says: Ahh! [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Jim says: Oh... oh! [Emotion: ['joy', 'anger'], Sarcasm: not_sarcastic] Dwight says: I have no feeling in my fingers or pen1s. But I think it was worth it. [Emotion: ['joy', 'love'], Sarcasm: not_sarcastic] Dwight says:  Haahh!!  [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Jim says: Um, I was laying on the ground,\"), Document(metadata={}, page_content=\"What's the first best? [Emotion: ['joy', 'anger'], Sarcasm: not_sarcastic] Nellie says:  Dwight?  Hello? Dwight? [Emotion: ['fear', 'anger'], Sarcasm: sarcastic] Jim says:  Is that Nellie? [Emotion: ['fear', 'anger'], Sarcasm: not_sarcastic] Dwight says:  Don't let-shh! [Emotion: ['fear', 'anger'], Sarcasm: not_sarcastic] Nellie says: Are you in there? I can see the light on under your door. Hello?   Oh, look at that. The light went off, just as I said the light went on. Hello?  Dwight?  Dwight.  [Emotion: ['fear', 'anger'], Sarcasm: not_sarcastic] Dwight says: Today is the test launch day for the inaugural Sabre store. Brr brr brr BRR  and I, Dwight Schrute, am in charge of the entire operation. If I can prove myself today and the store is a hit with the media and Nellie sees this, the\"), Document(metadata={}, page_content=\"Michael says: Woah, wow, who told you that? [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Dwight says: You did. Several times. Over and over again. [Emotion: ['anger', 'sadness'], Sarcasm: not_sarcastic] Michael says:  No, I don't think I ever did. That was your idea Dwight. [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Dwight says:  You were dressed as Willy Wonka so... [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Michael says: I'm not taking... I'm not taking... [Emotion: ['joy', 'anger'], Sarcasm: not_sarcastic] Dwight says: Wasn't my idea. Loved - but I can't. [Emotion: ['sadness', 'love'], Sarcasm: not_sarcastic] Michael says: Wait a second, wait a second, I wrote it down in my diary. [Emotion: ['anger', 'joy'], Sarcasm: not_sarcastic] Dwight says: You don't keep a\")], 'answer': '\"Ah, the beet-farming, Battlestar Galactica-watching, ninja-training, Assistant (to the) Regional Manager that I am, I can confidently say that I am the most superior being in this office. And if you don\\'t like it, you can just... [pauses for dramatic effect] ...Schrute it!\"'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572045b-ff0c-4033-adbe-fe2c5ac4139d",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09078272-425a-4a58-8f8e-2681ee6177b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(\n",
    "    inquiry,\n",
    "    retrieval_chain=react_retrieval_chain\n",
    "):\n",
    "    output = retrieval_chain.invoke({\"input\": inquiry})\n",
    "    print(output['answer'].strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cea3c1-9576-41fb-b8c6-10040b16323a",
   "metadata": {},
   "source": [
    "**inquiry 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8eccaa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, it seems that Andy is considered the funniest person in the office. He is quoted as saying \"Approved!\" and \"Chef from South Park, it's genius!\" which suggests that he has a good sense of humor and is able to make his coworkers laugh. Additionally, his sarcastic comments and jokes are met with laughter and amusement from the others.\n"
     ]
    }
   ],
   "source": [
    "print_output(\"Which person in the office is the funniest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f369bbc-0b6c-4356-bc61-c868c4e44598",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [RAG vs. Fine Tuning](https://www.youtube.com/watch?v=00Q0G84kq3M)\n",
    "2. [How to Use Langchain Chain Invoke: A Step-by-Step Guide](https://medium.com/@asakisakamoto02/how-to-use-langchain-chain-invoke-a-step-by-step-guide-9a6f129d77d1)\n",
    "3. [Implementing RAG using Langchain and Ollama](https://medium.com/@imabhi1216/implementing-rag-using-langchain-and-ollama-93bdf4a9027c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
